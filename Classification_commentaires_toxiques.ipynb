{"cells":[{"cell_type":"markdown","metadata":{"id":"_lyJzHuKRNWX"},"source":["# Importation des packages"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"MUj96QiIQsJ_"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package stopwords to C:\\Users\\Samy\n","[nltk_data]     Bouhelassa\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package wordnet to C:\\Users\\Samy\n","[nltk_data]     Bouhelassa\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package omw-1.4 to C:\\Users\\Samy\n","[nltk_data]     Bouhelassa\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package omw-1.4 is already up-to-date!\n"]},{"data":{"text/plain":["True"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","import tensorflow as tf\n","#import tensorflow_addons as tfa\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Embedding, LSTM, GlobalMaxPool1D, Dropout\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.stem import WordNetLemmatizer\n","\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","nltk.download('omw-1.4')"]},{"cell_type":"markdown","metadata":{"id":"xZLpUMItRWc0"},"source":["# Importation des données"]},{"cell_type":"markdown","metadata":{"id":"cbE3MzVKRaV2"},"source":["Ajoutez un raccourci de ce dossier à votre google drive :\n","\n","https://drive.google.com/drive/folders/1mx-CAzT10YKrmxHfYDP_1Oef7PVGUr7s?usp=sharing"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28361,"status":"ok","timestamp":1645597882479,"user":{"displayName":"Gautherot Morgan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07974205866322024288"},"user_tz":-60},"id":"4FktfCVaRVrs","outputId":"5b61276d-d759-4384-d8bb-08ed0b57ae69"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":2823,"status":"ok","timestamp":1645598103254,"user":{"displayName":"Gautherot Morgan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07974205866322024288"},"user_tz":-60},"id":"qky64Lq8Rocy","outputId":"3f57ca8f-59ae-4e38-e35d-a040b2e6a944"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>comment_text</th>\n","      <th>toxic</th>\n","      <th>severe_toxic</th>\n","      <th>obscene</th>\n","      <th>threat</th>\n","      <th>insult</th>\n","      <th>identity_hate</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0000997932d777bf</td>\n","      <td>Explanation\\nWhy the edits made under my usern...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>000103f0d9cfb60f</td>\n","      <td>D'aww! He matches this background colour I'm s...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>000113f07ec002fd</td>\n","      <td>Hey man, I'm really not trying to edit war. It...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0001b41b1c6bb37e</td>\n","      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0001d958c54c6e35</td>\n","      <td>You, sir, are my hero. Any chance you remember...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                 id                                       comment_text  toxic  \\\n","0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n","1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n","2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n","3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n","4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n","\n","   severe_toxic  obscene  threat  insult  identity_hate  \n","0             0        0       0       0              0  \n","1             0        0       0       0              0  \n","2             0        0       0       0              0  \n","3             0        0       0       0              0  \n","4             0        0       0       0              0  "]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["data = pd.read_csv('./data/train.csv')\n","data.head()"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[],"source":["# Lecture des données\n","train = pd.read_csv('./data/train.csv')\n","test = pd.read_csv('./data/test.csv')\n","\n","# On ne garde que les 5000 premiers exemples (pour les tests)\n","train = train[:15000]\n","\n","# On supprime la colonne 'id' qui ne nous sert pas\n","train = train.drop('id', axis=1)\n","\n","# Nombre de commentaires possédant un nombre de catégories\n","labels = train[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].values\n","labels = np.sum(labels, axis=1)"]},{"cell_type":"markdown","metadata":{"id":"-kUWzBzISpsK"},"source":["# Etude du jeu de données"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"CAexGL7jS-VF"},"outputs":[{"data":{"text/plain":["toxic            1439\n","severe_toxic      158\n","obscene           789\n","threat             50\n","insult            749\n","identity_hate     133\n","dtype: int64"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["# Your Code\n","\n","# On affiche le nombre de commentaires de chaque catégorie\n","train[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].sum()"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Commentaire pour la colonne toxic :\n","\"155487    know that Salivo sucks\n","Name: comment_text, dtype: object\"\n","\n","Commentaire pour la colonne severe_toxic :\n","\"82009    you're a dirty faggot \\n\\nlick my hairy nut sa...\n","Name: comment_text, dtype: object\"\n","\n","Commentaire pour la colonne obscene :\n","\"144671    Skins edits \\n\\nI see you went a bit mental ov...\n","Name: comment_text, dtype: object\"\n","\n","Commentaire pour la colonne threat :\n","\"155102    , death to vandalist of this Maratha sport\n","Name: comment_text, dtype: object\"\n","\n","Commentaire pour la colonne insult :\n","\"88605    I hate Season 4. If there's one thing I hate m...\n","Name: comment_text, dtype: object\"\n","\n","Commentaire pour la colonne identity_hate :\n","\"89577    Both of these two people are Gay kids and need...\n","Name: comment_text, dtype: object\"\n","\n"]}],"source":["# Affichage d'un commentaire aléatoire pour chaque catégorie\n","\n","for column in ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']:\n","    sample = data[data[column] == 1]['comment_text'].sample(1)\n","    print(f\"Commentaire pour la colonne {column} :\\n\\\"{sample}\\\"\\n\")"]},{"cell_type":"markdown","metadata":{"id":"YIzpSrAjSsAM"},"source":["# Préparation des données"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>comment_text</th>\n","      <th>toxic</th>\n","      <th>severe_toxic</th>\n","      <th>obscene</th>\n","      <th>threat</th>\n","      <th>insult</th>\n","      <th>identity_hate</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>explanation\\nwhy the edits made under my usern...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>d'aww! he matches this background colour i'm s...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>hey man, i'm really not trying to edit war. it...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>\"\\nmore\\ni can't make any real suggestions on ...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>you, sir, are my hero. any chance you remember...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                        comment_text  toxic  severe_toxic  \\\n","0  explanation\\nwhy the edits made under my usern...      0             0   \n","1  d'aww! he matches this background colour i'm s...      0             0   \n","2  hey man, i'm really not trying to edit war. it...      0             0   \n","3  \"\\nmore\\ni can't make any real suggestions on ...      0             0   \n","4  you, sir, are my hero. any chance you remember...      0             0   \n","\n","   obscene  threat  insult  identity_hate  \n","0        0       0       0              0  \n","1        0       0       0              0  \n","2        0       0       0              0  \n","3        0       0       0              0  \n","4        0       0       0              0  "]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["# On met les commentaires en minuscules\n","train['comment_text'] = train['comment_text'].str.lower()\n","\n","# Affichage des données\n","train.head()"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>comment_text</th>\n","      <th>toxic</th>\n","      <th>severe_toxic</th>\n","      <th>obscene</th>\n","      <th>threat</th>\n","      <th>insult</th>\n","      <th>identity_hate</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>[Explanation, Why, the, edits, made, under, my...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>[D, aww, He, matches, this, background, colour...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>[Hey, man, I, m, really, not, trying, to, edit...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>[More, I, can, t, make, any, real, suggestions...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>[You, sir, are, my, hero, Any, chance, you, re...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                        comment_text  toxic  severe_toxic  \\\n","0  [Explanation, Why, the, edits, made, under, my...      0             0   \n","1  [D, aww, He, matches, this, background, colour...      0             0   \n","2  [Hey, man, I, m, really, not, trying, to, edit...      0             0   \n","3  [More, I, can, t, make, any, real, suggestions...      0             0   \n","4  [You, sir, are, my, hero, Any, chance, you, re...      0             0   \n","\n","   obscene  threat  insult  identity_hate  \n","0        0       0       0              0  \n","1        0       0       0              0  \n","2        0       0       0              0  \n","3        0       0       0              0  \n","4        0       0       0              0  "]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["# On supprime les caractères spéciaux et on sépare les mots avec nltk\n","tokenizer = nltk.RegexpTokenizer(r'\\w+')\n","train['comment_text'] = data['comment_text'].apply(tokenizer.tokenize)\n","\n","train.head()"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>comment_text</th>\n","      <th>toxic</th>\n","      <th>severe_toxic</th>\n","      <th>obscene</th>\n","      <th>threat</th>\n","      <th>insult</th>\n","      <th>identity_hate</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>[Explanation, edits, made, username, Hardcore,...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>[aww, matches, background, colour, seemingly, ...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>[Hey, man, really, trying, edit, war, guy, con...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>[make, real, suggestions, improvement, wondere...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>[sir, hero, chance, remember, page]</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                        comment_text  toxic  severe_toxic  \\\n","0  [Explanation, edits, made, username, Hardcore,...      0             0   \n","1  [aww, matches, background, colour, seemingly, ...      0             0   \n","2  [Hey, man, really, trying, edit, war, guy, con...      0             0   \n","3  [make, real, suggestions, improvement, wondere...      0             0   \n","4                [sir, hero, chance, remember, page]      0             0   \n","\n","   obscene  threat  insult  identity_hate  \n","0        0       0       0              0  \n","1        0       0       0              0  \n","2        0       0       0              0  \n","3        0       0       0              0  \n","4        0       0       0              0  "]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["stopwords_list = set(stopwords.words('english'))\n","\n","# Fonction pour supprimer les stopwords\n","def remove_stopwords(word_list):\n","    filtered_words = [word for word in word_list if word.lower() not in stopwords_list]\n","    return filtered_words\n","\n","# Appliquer la fonction sur la colonne 'comment_text'\n","train['comment_text'] = train['comment_text'].apply(remove_stopwords)\n","\n","train.head()\n"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>comment_text</th>\n","      <th>toxic</th>\n","      <th>severe_toxic</th>\n","      <th>obscene</th>\n","      <th>threat</th>\n","      <th>insult</th>\n","      <th>identity_hate</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>[explanation, edits, made, username, hardcore,...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>[aww, match, background, colour, seemingly, st...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>[hey, man, really, trying, edit, war, guy, con...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>[make, real, suggestion, improvement, wondered...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>[sir, hero, chance, remember, page]</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                        comment_text  toxic  severe_toxic  \\\n","0  [explanation, edits, made, username, hardcore,...      0             0   \n","1  [aww, match, background, colour, seemingly, st...      0             0   \n","2  [hey, man, really, trying, edit, war, guy, con...      0             0   \n","3  [make, real, suggestion, improvement, wondered...      0             0   \n","4                [sir, hero, chance, remember, page]      0             0   \n","\n","   obscene  threat  insult  identity_hate  \n","0        0       0       0              0  \n","1        0       0       0              0  \n","2        0       0       0              0  \n","3        0       0       0              0  \n","4        0       0       0              0  "]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["# Initialiser le lemmatizer\n","lemmatizer = WordNetLemmatizer()\n","\n","# Fonction pour lemmatiser les mots\n","def lemmatize_words(word_list):\n","    lemmatized_words = [lemmatizer.lemmatize(word.lower()) for word in word_list]\n","    return lemmatized_words\n","\n","# Appliquer la fonction sur la colonne 'comment_text'\n","train['comment_text'] = train['comment_text'].apply(lemmatize_words)\n","\n","# Afficher les premières lignes du DataFrame après la lemmatisation\n","train.head()\n"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[{"data":{"text/plain":["['explanation edits made username hardcore metallica fan reverted vandalism closure gas voted new york doll fac please remove template talk page since retired 89 205 38 27',\n"," 'aww match background colour seemingly stuck thanks talk 21 51 january 11 2016 utc',\n"," 'hey man really trying edit war guy constantly removing relevant information talking edits instead talk page seems care formatting actual info']"]},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":["# Enfin, on reconstitue les phrases\n","sentences = list(map(lambda x : \" \".join(x), train['comment_text']))\n","\n","# Affichage des données\n","sentences[:3]"]},{"cell_type":"markdown","metadata":{"id":"LxNIQgESTCmE"},"source":["# Entraînement du modèle baseline"]},{"cell_type":"code","execution_count":41,"metadata":{"id":"YgkPpzIzSQUi"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train sequences shape : (13500, 42589)\n","Test sequences shape : (1500, 42589)\n","Train labels shape : (13500,)\n","Test labels shape : (1500,)\n"]}],"source":["# Pour le premier modèle, on va utiliser un Random Forest Classifier\n","# Avant cela, on va vectoriser les phrases avec TF-IDF\n","vectorizer = TfidfVectorizer()\n","\n","# On fit le vectorizer sur les phrases\n","vectorizer.fit(sentences)\n","\n","# On transforme les phrases en vecteurs\n","vectors = vectorizer.transform(sentences)\n","\n","# Séparation des données en train et test\n","train_vectors, test_vectors, train_labels, test_labels = train_test_split(vectors, labels, test_size=0.1, random_state=0)\n","\n","# Affichage des dimensions des données\n","print(f\"Train sequences shape : {train_vectors.shape}\")\n","print(f\"Test sequences shape : {test_vectors.shape}\")\n","print(f\"Train labels shape : {train_labels.shape}\")\n","print(f\"Test labels shape : {test_labels.shape}\")"]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy : 0.9133333333333333\n"]}],"source":["# Maintenant, on peut créer le modèle\n","model = RandomForestClassifier(n_estimators=15,random_state=0)\n","\n","# Entrainement du modèle\n","model.fit(train_vectors, train_labels)\n","\n","# Prédiction sur les données de test\n","predictions = model.predict(test_vectors)\n","\n","# Affichage de l'accuracy\n","print(f\"Accuracy : {accuracy_score(test_labels, predictions)}\")"]},{"cell_type":"markdown","metadata":{"id":"2a8IWbTFTHXh"},"source":["# Itération de la modélisation "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rVR0eCkoTQSI"},"outputs":[],"source":["# Your Code "]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMCSqKm9bskmrKsd3y9MwY2","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"}},"nbformat":4,"nbformat_minor":0}
