# NLP-CCT
Toxic Comment Classification for M1 ISEN

# Introduction

Le Natural Langage Processing (NLP) permet d’identifier les mots, les expressions, les phrases et les contextes associés à différents contextes de discriminations et de violences. En permettant ainsi de catégoriser en fonction de différents labels tels que le racisme, le sexisme, etc… Cette capacité à traiter et à interpréter de grandes quantités de données textuelles en temps réel est essentielle pour les plateformes en ligne cherchant à modérer efficacement leur contenu et à protéger leurs utilisateurs.
Dans le cadre du module de NLP en M1 à l’ISEN, nous avons travaillé sur ce problème. En visant à développer un modèle de classification de commentaires négatifs en différents labels, en mettant particulièrement l’accent sur la détection de discours haineux en tout genre.

# Tehcnologie

- [Google Colab](https://colab.research.google.com/)
- Tensorflow
- Keras
- Numpy
- Pandas
- NLTK
- Python
- [Embeddings GloVe](http://nlp.stanford.edu/data/glove.6B.zip)

# Sources

Le sujet de ce projet nous a été donné par [Morgan Gautherot](https://github.com/MorganGautherot/) et utilise les données du [Toxic Comment Classification Challenge](https://www.kaggle.com/competitions/jigsaw-toxic-comment-classification-challenge/data) qui a eu lieu sur la platforme [Kaggle](https://www.kaggle.com/).

# Auteurs 

Ce projet vous est proposé par [Samy](https://github.com/SamLouTan) et [Léo](https://github.com/Moobs12).
